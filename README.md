# ğŸŒ¿ ESG Extraction Pipeline â€“ Structured, Transparent & Reproducible  
> **Version 1.0 â€” November 2025**

## ğŸ“‹ Overview
This project develops a **reproducible ESG (Environmental, Social & Governance) data extraction pipeline** capable of extracting structured KPIs from *unstructured and semi-structured ESG reports*.  
Modern PDF extraction, NLP, and deterministic methods are combined in a layered architecture to reduce ambiguity in ESG disclosures.

While ESG reporting is crucial for achieving global sustainability objectives, the **lack of formatting standards, inconsistent units, and diverse narrative styles** makes automated extraction challenging.  
This project demonstrates a compact, fully transparent extraction framework using **synthetic sample reports**.

---

## ğŸ¯ Objectives
- Provide a **deterministic, testable extraction pipeline** for ESG KPIs.  
- Demonstrate hybrid extraction combining:  
  - Regex-based extraction  
  - Table recognizers (grid & plain)  
  - NLP window-based extraction  
  - Optional LLM fallback  
- Ensure all steps are **auditable, interpretable, and validated** via tests and notebooks.  
- Use **only synthetic PDF samples** for full reproducibility (no real PDFs required).

---

## ğŸ—ï¸ ESG KPI Framework

### Universal KPI Schema
Located in: `src/esg/schemas/universal_kpis.json`

This version tracks three core metrics:
- **Total GHG Emissions** (`tCO2e`)
- **Energy Consumption** (`MWh`)
- **Water Withdrawal** (`mÂ³`)

The schema includes aliases, keyword triggers, and unit variations.

---

## ğŸ” Extraction Architecture

| Layer | Component | Purpose |
|-------|-----------|----------|
| **1. Text Layer** | PDF reading (pdfplumber, PyMuPDF) | Robust text extraction |
| **2. Deterministic Extractors** | Regex, table-grid (Camelot), table-plain | High precision on structured data |
| **3. NLP Extractor** | Keyword windows, numeric parsing | Handles messy paragraphs |
| **4. Normalization** | Value parsing, unit resolution, scoring | Produces standardized KPI results |
| **5. Pipeline** | Orchestration & scoring | Generates final per-KPI outputs |
| **6. LLM Fallback (optional)** | gpt-4o-mini | For missing KPIs (disabled by default) |

---

## ğŸ§ª Test Suite

All extractors are validated using synthetic PDFs.  
Run:

```bash
pytest -q
```

Current status: **âœ” All tests passing**.

---

## ğŸ§© Project Structure

```
esg-llm-platform/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ samples/              # synthetic PDF sample reports
â”‚   â””â”€â”€ out/                  # extracted CSV results (sample PDFs only)
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ 01-notebook-test-pipeline.html
â”‚   â””â”€â”€ 02-notebook-analysis.html
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01-notebook-test-pipeline.ipynb
â”‚   â””â”€â”€ 02-notebook-analysis.ipynb
â”‚
â”œâ”€â”€ src/esg/
â”‚   â”œâ”€â”€ extractors/           # regex, nlp, tables, llm
â”‚   â”œâ”€â”€ normalization/        # unit/value normalization
â”‚   â”œâ”€â”€ utils/                # numeric parsing, pdf reader
â”‚   â”œâ”€â”€ pipeline/             # main pipeline logic
â”‚   â”œâ”€â”€ schemas/              # KPI definitions
â”‚   â””â”€â”€ cli/                  # command-line prototype
â”‚
â”œâ”€â”€ tests/                    # deterministic test suite
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â””â”€â”€ main.py
```

---

## ğŸ“Š Sample Report Evaluation

Using synthetic PDFs in `data/samples/`:

- 11 reports tested  
- Each contains controlled variations (messy units, OCR noise, corrupted tables, long narrative)  
- All KPIs successfully extracted in most reports  
- Confidence and source attribution provide transparency per extractor

A compact analysis appears in:

- `docs/02-notebook-analysis.html`

---

## ğŸ“ˆ Key Results (Synthetic Reports)

| KPI | Avg. Confidence | Best Extractor |
|------|----------------|----------------|
| Total GHG Emissions | ~0.75 | Regex / Table |
| Energy Consumption | ~0.70 | Regex |
| Water Withdrawal | ~0.70 | Table / Regex |

Missing values: **0%** on deterministic synthetic set.

---

## âš™ï¸ Tools & Libraries

- **PDF:** pdfplumber, PyMuPDF, Camelot, Ghostscript  
- **NLP:** keyword windows, regex, custom numeric parser  
- **Data:** pandas, numpy  
- **Visualization:** matplotlib (notebooks)  
- **LLM Fallback:** OpenAI API (disabled by default for reproducibility)  
- **Environment:** Python 3.12, `uv sync`, Jupyter notebooks  

---

## ğŸš€ Usage

### Setup
```bash
uv sync
```

### Run pipeline
```bash
python main.py --pdf data/samples/esg_simple_text.pdf
```

### Run test suite
```bash
pytest -q
```

### Recreate synthetic PDFs (optional)
```bash
uv run python data/samples/make_samples.py
```
> LLM generation is disabled by default for reproducibility.

---

## ğŸ“š Notebooks

| Notebook | Purpose |
|-----------|----------|
| `01-notebook-test-pipeline.ipynb` | Runs pipeline on all synthetic PDFs |
| `02-notebook-analysis.ipynb` | Aggregates CSV outputs â†’ confidence, completeness, source contribution |

HTML exports included in `docs/`.

---

## ğŸ“œ License
MIT License â€” free for use and modification with attribution.

---

## ğŸ‘¤ Author  
Developed by **Golib Sanaev**  
*Data Scientist | Applied AI & ESG Analytics*  

ğŸ“§ gsanaev80@gmail.com  
ğŸ”— LinkedIn: https://linkedin.com/in/golib-sanaev  
ğŸ’» GitHub: https://github.com/gsanaev

---

## ğŸ™ Acknowledgements

- [StackFuel](https://stackfuel.com/) â€” applied data science education  
- OpenAI GPT-5 Assistant â€” documentation, debugging, test design  


â­ *If you find this project useful, please give it a star!*
